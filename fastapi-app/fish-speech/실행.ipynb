{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecfcada5",
   "metadata": {},
   "source": [
    "# Ï†ÑÏ≤òÎ¶¨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71265da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Ï†ÑÏ≤òÎ¶¨ ÏôÑÎ£å: 8Í∞ú ÌååÏùºÏù¥ output_wavÏóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "\n",
    "def preprocess_wav_directory(input_dir, output_dir, sample_rate=16000):\n",
    "    input_dir = Path(input_dir)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for wav_file in input_dir.glob(\"*.wav\"):\n",
    "        output_file = output_dir / wav_file.name\n",
    "        command = [\n",
    "            \"ffmpeg\",\n",
    "            \"-y\",  # overwrite without asking\n",
    "            \"-i\", str(wav_file),\n",
    "            \"-ar\", str(sample_rate),       # Resample to 16kHz\n",
    "            \"-ac\", \"1\",                    # Convert to mono\n",
    "            \"-acodec\", \"pcm_s16le\",        # 16-bit PCM\n",
    "            str(output_file)\n",
    "        ]\n",
    "        subprocess.run(command, stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)\n",
    "\n",
    "    print(f\"‚úÖ Ï†ÑÏ≤òÎ¶¨ ÏôÑÎ£å: {len(list(output_dir.glob('*.wav')))}Í∞ú ÌååÏùºÏù¥ {output_dir}Ïóê Ï†ÄÏû•ÎêòÏóàÏäµÎãàÎã§.\")\n",
    "\n",
    "# ÏòàÏãú ÏÇ¨Ïö©\n",
    "input_path = 'input_wav'\n",
    "output_path = \"output_wav\"\n",
    "preprocess_wav_directory(input_path,output_path )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbeb2e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon May 26 00:48:39 2025       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 575.51.03              Driver Version: 575.51.03      CUDA Version: 12.9     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  Tesla T4                       Off |   00000001:00:00.0 Off |                  Off |\n",
      "| N/A   39C    P8              9W /   70W |       3MiB /  16384MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|  No running processes found                                                             |\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "/bin/bash: line 1: kill: (56231) - No such process\n"
     ]
    }
   ],
   "source": [
    "!sudo reboot\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "\n",
    "gc.collect()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652fd43c",
   "metadata": {},
   "source": [
    "# STT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86f4af17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéôÔ∏è STT Ïã§Ìñâ Ï§ë...\n",
      "üìù Ïù∏ÏãùÎêú ÌÖçÏä§Ìä∏: ÎÇòÎèÑ Ï†ÅÏßÄ ÏïäÏùÄ ÎÇòÏù¥Ïóê ÏßÄÍ∏àÍπåÏßÄ ÏÑ±Ïù∏Î≥ëÏóê ÎåÄÌï¥ Í≥µÎ∂ÄÌïòÍ≥† ÏûàÏñ¥Ïöî.\n"
     ]
    }
   ],
   "source": [
    "import azure.cognitiveservices.speech as speechsdk\n",
    "\n",
    "def transcribe_speech(audio_path: str, speech_key: str, region: str) -> str:\n",
    "    speech_config = speechsdk.SpeechConfig(subscription=speech_key, region=region)\n",
    "    speech_config.speech_recognition_language = \"ko-KR\"  # ‚úÖ ÌïúÍµ≠Ïñ¥ ÏÑ§Ï†ï\n",
    "\n",
    "    audio_config = speechsdk.audio.AudioConfig(filename=audio_path)\n",
    "\n",
    "    speech_recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)\n",
    "\n",
    "    print(\"üéôÔ∏è STT Ïã§Ìñâ Ï§ë...\")\n",
    "    result = speech_recognizer.recognize_once()\n",
    "\n",
    "    if result.reason == speechsdk.ResultReason.RecognizedSpeech:\n",
    "        print(\"üìù Ïù∏ÏãùÎêú ÌÖçÏä§Ìä∏:\", result.text)\n",
    "        return result.text\n",
    "    else:\n",
    "        print(\"‚ùå ÏùåÏÑ± Ïù∏Ïãù Ïã§Ìå®:\", result.reason)\n",
    "        return \"\"\n",
    "\n",
    "# ÏòàÏãú Ïã§Ìñâ\n",
    "speech_key = \"GG4wOUABvgwI2Im4ZFlBfX4H7N13tLCtJ8g6UHn2w5SV8n3A5HttJQQJ99BEACYeBjFXJ3w3AAAYACOGdyy5\"\n",
    "region = \"eastus\"\n",
    "prompt_audio_path = \"output_wav/ÎÖ∏Ïù∏ÎÇ®Ïó¨_ÎÖ∏Ïù∏ÎåÄÌôî07_F_1526682663_63_ÏàòÎèÑÍ∂å_Ïã§ÎÇ¥_08352.wav\"\n",
    "\n",
    "prompt_text = transcribe_speech(prompt_audio_path, speech_key, region)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5223a1a0",
   "metadata": {},
   "source": [
    "# TTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6312955e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-05-26 01:10:08.103\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m23\u001b[0m - \u001b[1mMerging checkpoints/fish-speech-1.5 and results/my_voice_project/checkpoints/step_000008000.ckpt into checkpoints/fish-speech-1.5-yth-lora-8000 with r_8_alpha_16\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:08.180\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m31\u001b[0m - \u001b[1mLoaded lora model with config LoraConfig(r=8, lora_alpha=16, lora_dropout=0.01)\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.410\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for embeddings.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for embeddings.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for codebook_embeddings.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for codebook_embeddings.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.0.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.1.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.411\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.2.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.3.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.4.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.412\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.5.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.6.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.413\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.7.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.8.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.9.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.414\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.10.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.11.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.12.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.415\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.13.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.14.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.15.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.416\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.16.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.17.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.18.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.417\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.19.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.20.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.21.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.418\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.22.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for layers.23.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for output.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for output.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_embeddings.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_embeddings.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.0.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.419\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.1.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.2.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wqkv.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wqkv.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wo.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.attention.wo.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w1.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w1.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w3.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w3.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w2.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.420\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_layers.3.feed_forward.w2.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.421\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_output.lora_A\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.421\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.models.text2semantic.llama\u001b[0m:\u001b[36mfrom_pretrained\u001b[0m:\u001b[36m450\u001b[0m - \u001b[33m\u001b[1mNo weight for fast_output.lora_B\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.433\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mLoaded llama model\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m67\u001b[0m - \u001b[1mFound 203 keys in llama model\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.598\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m68\u001b[0m - \u001b[1mFound 290 keys in lora model\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:21.609\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m72\u001b[0m - \u001b[1mMerged model loaded\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:26.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m77\u001b[0m - \u001b[1mSaved merged model to checkpoints/fish-speech-1.5-yth-lora-8000, validating\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:26.827\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m86\u001b[0m - \u001b[1mSignificant difference found in key: layers.14.attention.wqkv.weight\u001b[0m\n",
      "\u001b[32m2025-05-26 01:10:26.828\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmerge\u001b[0m:\u001b[36m94\u001b[0m - \u001b[1mMerged model is different from the original model, check passed\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python tools/llama/merge_lora.py \\\n",
    "    --lora-config r_8_alpha_16 \\\n",
    "    --base-weight checkpoints/fish-speech-1.5 \\\n",
    "    --lora-weight results/my_voice_project/checkpoints/step_000008000.ckpt \\\n",
    "    --output checkpoints/fish-speech-1.5-yth-lora-8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c87d0b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Checkpoint Keys ===\n",
      "model.embeddings.lora_A\n",
      "model.embeddings.lora_B\n",
      "model.codebook_embeddings.lora_A\n",
      "model.codebook_embeddings.lora_B\n",
      "model.layers.0.attention.wqkv.lora_A\n",
      "model.layers.0.attention.wqkv.lora_B\n",
      "model.layers.0.attention.wo.lora_A\n",
      "model.layers.0.attention.wo.lora_B\n",
      "model.layers.0.feed_forward.w1.lora_A\n",
      "model.layers.0.feed_forward.w1.lora_B\n",
      "model.layers.0.feed_forward.w3.lora_A\n",
      "model.layers.0.feed_forward.w3.lora_B\n",
      "model.layers.0.feed_forward.w2.lora_A\n",
      "model.layers.0.feed_forward.w2.lora_B\n",
      "model.layers.1.attention.wqkv.lora_A\n",
      "model.layers.1.attention.wqkv.lora_B\n",
      "model.layers.1.attention.wo.lora_A\n",
      "model.layers.1.attention.wo.lora_B\n",
      "model.layers.1.feed_forward.w1.lora_A\n",
      "model.layers.1.feed_forward.w1.lora_B\n",
      "model.layers.1.feed_forward.w3.lora_A\n",
      "model.layers.1.feed_forward.w3.lora_B\n",
      "model.layers.1.feed_forward.w2.lora_A\n",
      "model.layers.1.feed_forward.w2.lora_B\n",
      "model.layers.2.attention.wqkv.lora_A\n",
      "model.layers.2.attention.wqkv.lora_B\n",
      "model.layers.2.attention.wo.lora_A\n",
      "model.layers.2.attention.wo.lora_B\n",
      "model.layers.2.feed_forward.w1.lora_A\n",
      "model.layers.2.feed_forward.w1.lora_B\n",
      "model.layers.2.feed_forward.w3.lora_A\n",
      "model.layers.2.feed_forward.w3.lora_B\n",
      "model.layers.2.feed_forward.w2.lora_A\n",
      "model.layers.2.feed_forward.w2.lora_B\n",
      "model.layers.3.attention.wqkv.lora_A\n",
      "model.layers.3.attention.wqkv.lora_B\n",
      "model.layers.3.attention.wo.lora_A\n",
      "model.layers.3.attention.wo.lora_B\n",
      "model.layers.3.feed_forward.w1.lora_A\n",
      "model.layers.3.feed_forward.w1.lora_B\n",
      "model.layers.3.feed_forward.w3.lora_A\n",
      "model.layers.3.feed_forward.w3.lora_B\n",
      "model.layers.3.feed_forward.w2.lora_A\n",
      "model.layers.3.feed_forward.w2.lora_B\n",
      "model.layers.4.attention.wqkv.lora_A\n",
      "model.layers.4.attention.wqkv.lora_B\n",
      "model.layers.4.attention.wo.lora_A\n",
      "model.layers.4.attention.wo.lora_B\n",
      "model.layers.4.feed_forward.w1.lora_A\n",
      "model.layers.4.feed_forward.w1.lora_B\n",
      "model.layers.4.feed_forward.w3.lora_A\n",
      "model.layers.4.feed_forward.w3.lora_B\n",
      "model.layers.4.feed_forward.w2.lora_A\n",
      "model.layers.4.feed_forward.w2.lora_B\n",
      "model.layers.5.attention.wqkv.lora_A\n",
      "model.layers.5.attention.wqkv.lora_B\n",
      "model.layers.5.attention.wo.lora_A\n",
      "model.layers.5.attention.wo.lora_B\n",
      "model.layers.5.feed_forward.w1.lora_A\n",
      "model.layers.5.feed_forward.w1.lora_B\n",
      "model.layers.5.feed_forward.w3.lora_A\n",
      "model.layers.5.feed_forward.w3.lora_B\n",
      "model.layers.5.feed_forward.w2.lora_A\n",
      "model.layers.5.feed_forward.w2.lora_B\n",
      "model.layers.6.attention.wqkv.lora_A\n",
      "model.layers.6.attention.wqkv.lora_B\n",
      "model.layers.6.attention.wo.lora_A\n",
      "model.layers.6.attention.wo.lora_B\n",
      "model.layers.6.feed_forward.w1.lora_A\n",
      "model.layers.6.feed_forward.w1.lora_B\n",
      "model.layers.6.feed_forward.w3.lora_A\n",
      "model.layers.6.feed_forward.w3.lora_B\n",
      "model.layers.6.feed_forward.w2.lora_A\n",
      "model.layers.6.feed_forward.w2.lora_B\n",
      "model.layers.7.attention.wqkv.lora_A\n",
      "model.layers.7.attention.wqkv.lora_B\n",
      "model.layers.7.attention.wo.lora_A\n",
      "model.layers.7.attention.wo.lora_B\n",
      "model.layers.7.feed_forward.w1.lora_A\n",
      "model.layers.7.feed_forward.w1.lora_B\n",
      "model.layers.7.feed_forward.w3.lora_A\n",
      "model.layers.7.feed_forward.w3.lora_B\n",
      "model.layers.7.feed_forward.w2.lora_A\n",
      "model.layers.7.feed_forward.w2.lora_B\n",
      "model.layers.8.attention.wqkv.lora_A\n",
      "model.layers.8.attention.wqkv.lora_B\n",
      "model.layers.8.attention.wo.lora_A\n",
      "model.layers.8.attention.wo.lora_B\n",
      "model.layers.8.feed_forward.w1.lora_A\n",
      "model.layers.8.feed_forward.w1.lora_B\n",
      "model.layers.8.feed_forward.w3.lora_A\n",
      "model.layers.8.feed_forward.w3.lora_B\n",
      "model.layers.8.feed_forward.w2.lora_A\n",
      "model.layers.8.feed_forward.w2.lora_B\n",
      "model.layers.9.attention.wqkv.lora_A\n",
      "model.layers.9.attention.wqkv.lora_B\n",
      "model.layers.9.attention.wo.lora_A\n",
      "model.layers.9.attention.wo.lora_B\n",
      "model.layers.9.feed_forward.w1.lora_A\n",
      "model.layers.9.feed_forward.w1.lora_B\n",
      "model.layers.9.feed_forward.w3.lora_A\n",
      "model.layers.9.feed_forward.w3.lora_B\n",
      "model.layers.9.feed_forward.w2.lora_A\n",
      "model.layers.9.feed_forward.w2.lora_B\n",
      "model.layers.10.attention.wqkv.lora_A\n",
      "model.layers.10.attention.wqkv.lora_B\n",
      "model.layers.10.attention.wo.lora_A\n",
      "model.layers.10.attention.wo.lora_B\n",
      "model.layers.10.feed_forward.w1.lora_A\n",
      "model.layers.10.feed_forward.w1.lora_B\n",
      "model.layers.10.feed_forward.w3.lora_A\n",
      "model.layers.10.feed_forward.w3.lora_B\n",
      "model.layers.10.feed_forward.w2.lora_A\n",
      "model.layers.10.feed_forward.w2.lora_B\n",
      "model.layers.11.attention.wqkv.lora_A\n",
      "model.layers.11.attention.wqkv.lora_B\n",
      "model.layers.11.attention.wo.lora_A\n",
      "model.layers.11.attention.wo.lora_B\n",
      "model.layers.11.feed_forward.w1.lora_A\n",
      "model.layers.11.feed_forward.w1.lora_B\n",
      "model.layers.11.feed_forward.w3.lora_A\n",
      "model.layers.11.feed_forward.w3.lora_B\n",
      "model.layers.11.feed_forward.w2.lora_A\n",
      "model.layers.11.feed_forward.w2.lora_B\n",
      "model.layers.12.attention.wqkv.lora_A\n",
      "model.layers.12.attention.wqkv.lora_B\n",
      "model.layers.12.attention.wo.lora_A\n",
      "model.layers.12.attention.wo.lora_B\n",
      "model.layers.12.feed_forward.w1.lora_A\n",
      "model.layers.12.feed_forward.w1.lora_B\n",
      "model.layers.12.feed_forward.w3.lora_A\n",
      "model.layers.12.feed_forward.w3.lora_B\n",
      "model.layers.12.feed_forward.w2.lora_A\n",
      "model.layers.12.feed_forward.w2.lora_B\n",
      "model.layers.13.attention.wqkv.lora_A\n",
      "model.layers.13.attention.wqkv.lora_B\n",
      "model.layers.13.attention.wo.lora_A\n",
      "model.layers.13.attention.wo.lora_B\n",
      "model.layers.13.feed_forward.w1.lora_A\n",
      "model.layers.13.feed_forward.w1.lora_B\n",
      "model.layers.13.feed_forward.w3.lora_A\n",
      "model.layers.13.feed_forward.w3.lora_B\n",
      "model.layers.13.feed_forward.w2.lora_A\n",
      "model.layers.13.feed_forward.w2.lora_B\n",
      "model.layers.14.attention.wqkv.lora_A\n",
      "model.layers.14.attention.wqkv.lora_B\n",
      "model.layers.14.attention.wo.lora_A\n",
      "model.layers.14.attention.wo.lora_B\n",
      "model.layers.14.feed_forward.w1.lora_A\n",
      "model.layers.14.feed_forward.w1.lora_B\n",
      "model.layers.14.feed_forward.w3.lora_A\n",
      "model.layers.14.feed_forward.w3.lora_B\n",
      "model.layers.14.feed_forward.w2.lora_A\n",
      "model.layers.14.feed_forward.w2.lora_B\n",
      "model.layers.15.attention.wqkv.lora_A\n",
      "model.layers.15.attention.wqkv.lora_B\n",
      "model.layers.15.attention.wo.lora_A\n",
      "model.layers.15.attention.wo.lora_B\n",
      "model.layers.15.feed_forward.w1.lora_A\n",
      "model.layers.15.feed_forward.w1.lora_B\n",
      "model.layers.15.feed_forward.w3.lora_A\n",
      "model.layers.15.feed_forward.w3.lora_B\n",
      "model.layers.15.feed_forward.w2.lora_A\n",
      "model.layers.15.feed_forward.w2.lora_B\n",
      "model.layers.16.attention.wqkv.lora_A\n",
      "model.layers.16.attention.wqkv.lora_B\n",
      "model.layers.16.attention.wo.lora_A\n",
      "model.layers.16.attention.wo.lora_B\n",
      "model.layers.16.feed_forward.w1.lora_A\n",
      "model.layers.16.feed_forward.w1.lora_B\n",
      "model.layers.16.feed_forward.w3.lora_A\n",
      "model.layers.16.feed_forward.w3.lora_B\n",
      "model.layers.16.feed_forward.w2.lora_A\n",
      "model.layers.16.feed_forward.w2.lora_B\n",
      "model.layers.17.attention.wqkv.lora_A\n",
      "model.layers.17.attention.wqkv.lora_B\n",
      "model.layers.17.attention.wo.lora_A\n",
      "model.layers.17.attention.wo.lora_B\n",
      "model.layers.17.feed_forward.w1.lora_A\n",
      "model.layers.17.feed_forward.w1.lora_B\n",
      "model.layers.17.feed_forward.w3.lora_A\n",
      "model.layers.17.feed_forward.w3.lora_B\n",
      "model.layers.17.feed_forward.w2.lora_A\n",
      "model.layers.17.feed_forward.w2.lora_B\n",
      "model.layers.18.attention.wqkv.lora_A\n",
      "model.layers.18.attention.wqkv.lora_B\n",
      "model.layers.18.attention.wo.lora_A\n",
      "model.layers.18.attention.wo.lora_B\n",
      "model.layers.18.feed_forward.w1.lora_A\n",
      "model.layers.18.feed_forward.w1.lora_B\n",
      "model.layers.18.feed_forward.w3.lora_A\n",
      "model.layers.18.feed_forward.w3.lora_B\n",
      "model.layers.18.feed_forward.w2.lora_A\n",
      "model.layers.18.feed_forward.w2.lora_B\n",
      "model.layers.19.attention.wqkv.lora_A\n",
      "model.layers.19.attention.wqkv.lora_B\n",
      "model.layers.19.attention.wo.lora_A\n",
      "model.layers.19.attention.wo.lora_B\n",
      "model.layers.19.feed_forward.w1.lora_A\n",
      "model.layers.19.feed_forward.w1.lora_B\n",
      "model.layers.19.feed_forward.w3.lora_A\n",
      "model.layers.19.feed_forward.w3.lora_B\n",
      "model.layers.19.feed_forward.w2.lora_A\n",
      "model.layers.19.feed_forward.w2.lora_B\n",
      "model.layers.20.attention.wqkv.lora_A\n",
      "model.layers.20.attention.wqkv.lora_B\n",
      "model.layers.20.attention.wo.lora_A\n",
      "model.layers.20.attention.wo.lora_B\n",
      "model.layers.20.feed_forward.w1.lora_A\n",
      "model.layers.20.feed_forward.w1.lora_B\n",
      "model.layers.20.feed_forward.w3.lora_A\n",
      "model.layers.20.feed_forward.w3.lora_B\n",
      "model.layers.20.feed_forward.w2.lora_A\n",
      "model.layers.20.feed_forward.w2.lora_B\n",
      "model.layers.21.attention.wqkv.lora_A\n",
      "model.layers.21.attention.wqkv.lora_B\n",
      "model.layers.21.attention.wo.lora_A\n",
      "model.layers.21.attention.wo.lora_B\n",
      "model.layers.21.feed_forward.w1.lora_A\n",
      "model.layers.21.feed_forward.w1.lora_B\n",
      "model.layers.21.feed_forward.w3.lora_A\n",
      "model.layers.21.feed_forward.w3.lora_B\n",
      "model.layers.21.feed_forward.w2.lora_A\n",
      "model.layers.21.feed_forward.w2.lora_B\n",
      "model.layers.22.attention.wqkv.lora_A\n",
      "model.layers.22.attention.wqkv.lora_B\n",
      "model.layers.22.attention.wo.lora_A\n",
      "model.layers.22.attention.wo.lora_B\n",
      "model.layers.22.feed_forward.w1.lora_A\n",
      "model.layers.22.feed_forward.w1.lora_B\n",
      "model.layers.22.feed_forward.w3.lora_A\n",
      "model.layers.22.feed_forward.w3.lora_B\n",
      "model.layers.22.feed_forward.w2.lora_A\n",
      "model.layers.22.feed_forward.w2.lora_B\n",
      "model.layers.23.attention.wqkv.lora_A\n",
      "model.layers.23.attention.wqkv.lora_B\n",
      "model.layers.23.attention.wo.lora_A\n",
      "model.layers.23.attention.wo.lora_B\n",
      "model.layers.23.feed_forward.w1.lora_A\n",
      "model.layers.23.feed_forward.w1.lora_B\n",
      "model.layers.23.feed_forward.w3.lora_A\n",
      "model.layers.23.feed_forward.w3.lora_B\n",
      "model.layers.23.feed_forward.w2.lora_A\n",
      "model.layers.23.feed_forward.w2.lora_B\n",
      "model.output.lora_A\n",
      "model.output.lora_B\n",
      "model.fast_embeddings.lora_A\n",
      "model.fast_embeddings.lora_B\n",
      "model.fast_layers.0.attention.wqkv.lora_A\n",
      "model.fast_layers.0.attention.wqkv.lora_B\n",
      "model.fast_layers.0.attention.wo.lora_A\n",
      "model.fast_layers.0.attention.wo.lora_B\n",
      "model.fast_layers.0.feed_forward.w1.lora_A\n",
      "model.fast_layers.0.feed_forward.w1.lora_B\n",
      "model.fast_layers.0.feed_forward.w3.lora_A\n",
      "model.fast_layers.0.feed_forward.w3.lora_B\n",
      "model.fast_layers.0.feed_forward.w2.lora_A\n",
      "model.fast_layers.0.feed_forward.w2.lora_B\n",
      "model.fast_layers.1.attention.wqkv.lora_A\n",
      "model.fast_layers.1.attention.wqkv.lora_B\n",
      "model.fast_layers.1.attention.wo.lora_A\n",
      "model.fast_layers.1.attention.wo.lora_B\n",
      "model.fast_layers.1.feed_forward.w1.lora_A\n",
      "model.fast_layers.1.feed_forward.w1.lora_B\n",
      "model.fast_layers.1.feed_forward.w3.lora_A\n",
      "model.fast_layers.1.feed_forward.w3.lora_B\n",
      "model.fast_layers.1.feed_forward.w2.lora_A\n",
      "model.fast_layers.1.feed_forward.w2.lora_B\n",
      "model.fast_layers.2.attention.wqkv.lora_A\n",
      "model.fast_layers.2.attention.wqkv.lora_B\n",
      "model.fast_layers.2.attention.wo.lora_A\n",
      "model.fast_layers.2.attention.wo.lora_B\n",
      "model.fast_layers.2.feed_forward.w1.lora_A\n",
      "model.fast_layers.2.feed_forward.w1.lora_B\n",
      "model.fast_layers.2.feed_forward.w3.lora_A\n",
      "model.fast_layers.2.feed_forward.w3.lora_B\n",
      "model.fast_layers.2.feed_forward.w2.lora_A\n",
      "model.fast_layers.2.feed_forward.w2.lora_B\n",
      "model.fast_layers.3.attention.wqkv.lora_A\n",
      "model.fast_layers.3.attention.wqkv.lora_B\n",
      "model.fast_layers.3.attention.wo.lora_A\n",
      "model.fast_layers.3.attention.wo.lora_B\n",
      "model.fast_layers.3.feed_forward.w1.lora_A\n",
      "model.fast_layers.3.feed_forward.w1.lora_B\n",
      "model.fast_layers.3.feed_forward.w3.lora_A\n",
      "model.fast_layers.3.feed_forward.w3.lora_B\n",
      "model.fast_layers.3.feed_forward.w2.lora_A\n",
      "model.fast_layers.3.feed_forward.w2.lora_B\n",
      "model.fast_output.lora_A\n",
      "model.fast_output.lora_B\n",
      "\n",
      "Ï¥ù LoRA Í¥ÄÎ†® key Í∞úÏàò: 290\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "ckpt_path = \"results/my_voice_project/checkpoints/step_000008000.ckpt\"\n",
    "\n",
    "ckpt = torch.load(ckpt_path, map_location=\"cpu\", weights_only=False)\n",
    "\n",
    "print(\"=== Checkpoint Keys ===\")\n",
    "for k in ckpt[\"state_dict\"].keys():\n",
    "    if \"lora\" in k:\n",
    "        print(k)\n",
    "\n",
    "print(\"\\nÏ¥ù LoRA Í¥ÄÎ†® key Í∞úÏàò:\", len([k for k in ckpt[\"state_dict\"].keys() if \"lora\" in k]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52019823",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/fish-work/fish-conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2025-05-29 02:33:32.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m681\u001b[0m - \u001b[1mRestored model from checkpoint\u001b[0m\n",
      "\u001b[32m2025-05-29 02:33:32.656\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m687\u001b[0m - \u001b[1mUsing DualARTransformer\u001b[0m\n",
      "/mnt/fish-work/fish-conda/lib/python3.10/site-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:445: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/mnt/fish-work/fish-conda/lib/python3.10/site-packages/vector_quantize_pytorch/vector_quantize_pytorch.py:630: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/mnt/fish-work/fish-conda/lib/python3.10/site-packages/vector_quantize_pytorch/finite_scalar_quantization.py:147: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "/mnt/fish-work/fish-conda/lib/python3.10/site-packages/vector_quantize_pytorch/lookup_free_quantization.py:209: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  @autocast(enabled = False)\n",
      "\u001b[32m2025-05-29 02:33:33.619\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.vqgan.inference\u001b[0m:\u001b[36mload_model\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mLoaded model: <All keys matched successfully>\u001b[0m\n",
      "\u001b[32m2025-05-29 02:33:33.626\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m43\u001b[0m - \u001b[1mLoaded audio with 7.25 seconds\u001b[0m\n",
      "/mnt/fish-work/fish-conda/lib/python3.10/site-packages/vector_quantize_pytorch/residual_fsq.py:170: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(enabled = False):\n",
      "\u001b[32m2025-05-29 02:33:33.890\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.inference_engine.vq_manager\u001b[0m:\u001b[36mencode_reference\u001b[0m:\u001b[36m50\u001b[0m - \u001b[1mEncoded prompt: torch.Size([8, 156])\u001b[0m\n",
      "\u001b[32m2025-05-29 02:33:33.892\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mfish_speech.inference_engine\u001b[0m:\u001b[36minference\u001b[0m:\u001b[36m62\u001b[0m - \u001b[33m\u001b[1mset seed: 0\u001b[0m\n",
      "\u001b[32m2025-05-29 02:33:33.911\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: Ïù¥ ÏÇ¨ÏßÑÏùÄ ÎÇ¥Í∞Ä Ïä§Î¨¥ ÏÇ¥ Îïå, Ï≤òÏùå ÏÑúÏö∏ Íµ¨Í≤Ω Í∞îÏùÑ Îïå Ï∞çÏùÄ Í±∞Ïïº.\n",
      "Ï†ÄÍ∏∞ ÏòÜÏóê ÏûàÎäî ÏπúÍµ¨Îäî ÏàúÏù¥, Ï∞∏ ÎßêÎèÑ ÎßéÍ≥† ÏõÉÏùåÎèÑ ÎßéÎçò ÏïÑÏù¥ÏòÄÏßÄ.\u001b[0m\n",
      "\u001b[32m2025-05-29 02:33:33.918\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: Í∑∏ÎÇ† ÎÇ®ÎåÄÎ¨∏ÏãúÏû•ÏóêÏÑú ÏÇ∞ ÌïòÎäòÏÉâ ÏõêÌîºÏä§Î•º ÏïÑÏßÅÎèÑ Í∏∞ÏñµÌï¥.\n",
      "ÏÇ¨ÏßÑ ÏÜç ÎÇòÎäî Ï∞∏ Ìï¥ÎßëÏùÄÎç∞, Í∑∏Îïê ÏÑ∏ÏÉÅÏù¥ Îã§ ÏÑ§Î†àÍ≥† Ïã†Í∏∞ÌñàÏßÄ.\u001b[0m\n",
      "\u001b[32m2025-05-29 02:33:33.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m788\u001b[0m - \u001b[1mEncoded text: ÏöîÏ¶òÎèÑ Ïù¥ ÏÇ¨ÏßÑ Î≥¥Î©¥ Í∞ÄÎÅî Í∑∏ ÏãúÏ†à ÎÉÑÏÉàÍ∞Ä ÎÇòÎäî Í≤É Í∞ôÏïÑ.\u001b[0m\n",
      "\u001b[32m2025-05-29 02:33:33.926\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 1/3 of sample 1/1\u001b[0m\n",
      "  0%|          | 0/7960 [00:00<?, ?it/s]/mnt/fish-work/fish-conda/lib/python3.10/contextlib.py:103: FutureWarning: `torch.backends.cuda.sdp_kernel()` is deprecated. In the future, this context manager will be removed. Please see `torch.nn.attention.sdpa_kernel()` for the new context manager, with updated signature.\n",
      "  self.gen = func(*args, **kwds)\n",
      "  1%|          | 58/7960 [00:04<09:26, 13.94it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 20\u001b[0m\n\u001b[1;32m     14\u001b[0m prompt_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mÏòàÏãú ÌîÑÎ°¨Ìè¨Ìä∏ ÏûÖÎãàÎã§.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# prompt_text = \"\"\"Ï±ÖÏù¥ ÏòàÏà†ÌíàÏ≤òÎüº ÏòàÏÅòÍ≤å ÎßåÎì§Ïñ¥ÏßÄÎäî ÏãúÎåÄÏù∏Îç∞, ÎÇ¥Í∞Ä ÏßÅÏ†ë ÌÉÄÏù¥ÌïëÌïòÍ≥†, ÍµêÏ†ï Î≥¥Í≥†, ÏõåÎìúÎ°ú Ìé∏ÏßëÌïòÍ≥†, ÎîîÏûêÏù∏ÍπåÏßÄ Íµ¨ÏÉÅÌïòÎ©∞ ÎßåÎì§ÏóàÏúºÎãàÍπå ÏûêÏÑúÏ†ÑÏùò Í≤âÎ™®ÏäµÏùÄ ÌèâÎ≤îÌïòÍ≥† ÏÜåÎ∞ïÌñàÏñ¥. Í∑∏ÎûòÎèÑ Ïñ¥Î®∏ÎãàÍªòÏÑúÎäî ÏùºÏÉùÏù¥ Í≥†Ïä§ÎûÄÌûà Îã¥Í∏¥ Ï±ÖÏùÑ Î∞õÏïÑÎì§Í≥†Îäî Î¨¥Ï≤ô Ïã†Í∏∞Ìï¥ÌïòÍ≥† Í∏∞ÎªêÌïòÏÖ®Ïñ¥.\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Ïñ¥Î®∏ÎãàÎäî Î∞∞Ïö∏ Í∏∞ÌöåÎ•º ÎßéÏù¥ Í∞ñÏßÄ Î™ªÌñàÏßÄÎßå Îäò Ï±ÖÏùÑ Í∞ÄÍπåÏù¥ÌïòÏÖ®Ïñ¥. ÏÇ≠ÎßâÌïòÍ≥† Îî±Îî±Ìïú ÏãúÎåÅÏùò Î¨∏ÌôîÏóê, Í≥µÎ¨¥Ïõê ÎÇ®Ìé∏Ïùò Î∞ïÎ¥âÏóê ÍøãÍøãÏù¥ ÎßûÏÑú ÏùºÏÉùÏùÑ Ï¢ÄÎçî ÌôúÍ∏∞Ï∞®Í≤å ÏÇ¨ÏÖ®Í≥† ÌäπÌûà Í∞ïÎã® ÏûàÍ≥† ÏöîÎ†π ÏûàÍ≤å ÏÑ∏ÏÉÅÍ≥º ÎßûÏß± Îñ†ÏÑú Í≥†Îã®ÌïòÎçò Í∞ÄÎÇúÏùÑ ÎÅäÏñ¥ÎÇ¥ÏÖ®Ïñ¥. ÏûêÏãù ÏÇº ÌòïÏ†úÎ•º Ï§ëÏÇ∞Ï∏µÏúºÎ°ú Ï¢Ä ÎßåÎì§Ïñ¥ÎëêÏãúÍ≥†, Ï±ÖÏûÑ ÏôÑÏàòÌïòÏã† ÏïÑÎ≤ÑÎãòÍªòÏÑú ÌôÄÍ∞ÄÎ∂ÑÌïú ÎßàÏùåÏúºÎ°ú Î®ºÏ†Ä Í∞ÄÏãúÎèÑÎ°ù Ïûò Î≥¥ÎÇ¥ÎìúÎ¶∞ ÌõÑÏóê Ïù¥Ï†ú Ïã†ÏïôÏóê Í∏∞ÎåÄÏñ¥ Îã®Ï†ïÌïú ÎÖ∏ÎÖÑÏùÑ Î≥¥ÎÇ¥Í≥† Í≥ÑÏÖî\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# Í∑∏Îü¨Îçò Ïñ¥Î®∏ÎãàÍªòÏÑú Ïñ∏Ï††Í∞ÄÎ∂ÄÌÑ∞ ÎÇ¥Í∞Ä Ïì∞ÏßÄ ÏïäÎäîÎã§Î©¥ÏÑú Í∞ÄÏ†∏Îã§ ÎìúÎ¶∞ Îπà Í≥µÏ±ÖÏóê Ïó∞ÌïÑÎ°ú ÍæπÍæπ ÎàåÎü¨Í∞ÄÎ©¥ÏÑú ÏßÄÎÇòÏò® Ïù¥ÏïºÍ∏∞Îì§ÏùÑ Í∏∞ÏñµÎÇòÎäî ÎåÄÎ°ú Ï°∞Í∏àÏî© Ïì∞Í∏∞ ÏãúÏûëÌïòÏÖ®ÎäîÎç∞, ÍπîÎÅîÌïòÍ≤å Ï†ïÎ¶¨Ìï¥ÏÑú Ï±ÖÏúºÎ°ú ÎßåÎì§Ïñ¥ ÎìúÎ¶¨Í≤†Îã§Î©∞ ÏõêÍ≥†Î•º Í∞ÄÏ†∏Îã§Í∞Ä ÌÉÄÏù¥ÌïëÌïòÍ∏∞ ÏãúÏûëÌñàÏñ¥\"\"\"\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 3. Ï∂îÎ°† Ïã§Ìñâ\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m sample_rate, waveform \u001b[38;5;241m=\u001b[39m \u001b[43mrun_tts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_audio_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt_text\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# 4. float32 ‚Üí int16Î°ú Î≥ÄÌôòÌïòÏó¨ Ï†ÄÏû•\u001b[39;00m\n\u001b[1;32m     23\u001b[0m waveform_int16 \u001b[38;5;241m=\u001b[39m (waveform \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m32767\u001b[39m)\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint16)\n",
      "File \u001b[0;32m/mnt/fish-speech-copy/inference_module.py:71\u001b[0m, in \u001b[0;36mrun_tts\u001b[0;34m(engine, input_text, prompt_audio_path, prompt_text)\u001b[0m\n\u001b[1;32m     55\u001b[0m     references \u001b[38;5;241m=\u001b[39m [ServeReferenceAudio(audio\u001b[38;5;241m=\u001b[39maudio_bytes, text\u001b[38;5;241m=\u001b[39mprompt_text)]\n\u001b[1;32m     57\u001b[0m request \u001b[38;5;241m=\u001b[39m ServeTTSRequest(\n\u001b[1;32m     58\u001b[0m     text\u001b[38;5;241m=\u001b[39minput_text,\n\u001b[1;32m     59\u001b[0m     reference_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwav\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     69\u001b[0m )\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m result \u001b[38;5;129;01min\u001b[39;00m engine\u001b[38;5;241m.\u001b[39minference(request):\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mcode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfinal\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     73\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39maudio  \u001b[38;5;66;03m# -> (sample_rate: int, waveform: np.ndarray)\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/fish-work/fish-conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:36\u001b[0m, in \u001b[0;36m_wrap_generator.<locals>.generator_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;66;03m# Issuing `None` to a generator fires it up\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m---> 36\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     40\u001b[0m             \u001b[38;5;66;03m# Forward the response to our caller and get its next request\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/fish-speech-copy/fish_speech/inference_engine/__init__.py:85\u001b[0m, in \u001b[0;36mTTSInferenceEngine.inference\u001b[0;34m(self, req)\u001b[0m\n\u001b[1;32m     81\u001b[0m segments \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;66;03m# Get the response from the LLAMA model\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     wrapped_result: WrappedGenerateResponse \u001b[38;5;241m=\u001b[39m \u001b[43mresponse_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     86\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wrapped_result\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     87\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m InferenceResult(\n\u001b[1;32m     88\u001b[0m             code\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     89\u001b[0m             audio\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     94\u001b[0m             ),\n\u001b[1;32m     95\u001b[0m         )\n",
      "File \u001b[0;32m/mnt/fish-work/fish-conda/lib/python3.10/queue.py:171\u001b[0m, in \u001b[0;36mQueue.get\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    170\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_qsize():\n\u001b[0;32m--> 171\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnot_empty\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m timeout \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m must be a non-negative number\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/mnt/fish-work/fish-conda/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|‚ñç         | 310/7960 [00:22<09:19, 13.66it/s]\n",
      "\u001b[32m2025-05-29 02:33:57.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m860\u001b[0m - \u001b[1mGenerated 312 tokens in 23.18 seconds, 13.46 tokens/sec\u001b[0m\n",
      "\u001b[32m2025-05-29 02:33:57.109\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m863\u001b[0m - \u001b[1mBandwidth achieved: 8.59 GB/s\u001b[0m\n",
      "\u001b[32m2025-05-29 02:33:57.110\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m868\u001b[0m - \u001b[1mGPU Memory used: 2.09 GB\u001b[0m\n",
      "\u001b[32m2025-05-29 02:33:57.111\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mfish_speech.models.text2semantic.inference\u001b[0m:\u001b[36mgenerate_long\u001b[0m:\u001b[36m806\u001b[0m - \u001b[1mGenerating sentence 2/3 of sample 1/1\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from inference_module import init_engine, run_tts\n",
    "import numpy as np\n",
    "from scipy.io.wavfile import write as write_wav\n",
    "engine = init_engine()\n",
    "\n",
    "input_text = \"\"\"\n",
    "Ïù¥ ÏÇ¨ÏßÑÏùÄ ÎÇ¥Í∞Ä Ïä§Î¨¥ ÏÇ¥ Îïå, Ï≤òÏùå ÏÑúÏö∏ Íµ¨Í≤Ω Í∞îÏùÑ Îïå Ï∞çÏùÄ Í±∞Ïïº.\n",
    "Ï†ÄÍ∏∞ ÏòÜÏóê ÏûàÎäî ÏπúÍµ¨Îäî ÏàúÏù¥, Ï∞∏ ÎßêÎèÑ ÎßéÍ≥† ÏõÉÏùåÎèÑ ÎßéÎçò ÏïÑÏù¥ÏòÄÏßÄ.\n",
    "Í∑∏ÎÇ† ÎÇ®ÎåÄÎ¨∏ÏãúÏû•ÏóêÏÑú ÏÇ∞ ÌïòÎäòÏÉâ ÏõêÌîºÏä§Î•º ÏïÑÏßÅÎèÑ Í∏∞ÏñµÌï¥.\n",
    "ÏÇ¨ÏßÑ ÏÜç ÎÇòÎäî Ï∞∏ Ìï¥ÎßëÏùÄÎç∞, Í∑∏Îïê ÏÑ∏ÏÉÅÏù¥ Îã§ ÏÑ§Î†àÍ≥† Ïã†Í∏∞ÌñàÏßÄ.\n",
    "ÏöîÏ¶òÎèÑ Ïù¥ ÏÇ¨ÏßÑ Î≥¥Î©¥ Í∞ÄÎÅî Í∑∏ ÏãúÏ†à ÎÉÑÏÉàÍ∞Ä ÎÇòÎäî Í≤É Í∞ôÏïÑ.\n",
    "\"\"\"\n",
    "prompt_audio_path = \"input_wav/test.wav\"\n",
    "prompt_text = 'ÏòàÏãú ÌîÑÎ°¨Ìè¨Ìä∏ ÏûÖÎãàÎã§.'\n",
    "# prompt_text = \"\"\"Ï±ÖÏù¥ ÏòàÏà†ÌíàÏ≤òÎüº ÏòàÏÅòÍ≤å ÎßåÎì§Ïñ¥ÏßÄÎäî ÏãúÎåÄÏù∏Îç∞, ÎÇ¥Í∞Ä ÏßÅÏ†ë ÌÉÄÏù¥ÌïëÌïòÍ≥†, ÍµêÏ†ï Î≥¥Í≥†, ÏõåÎìúÎ°ú Ìé∏ÏßëÌïòÍ≥†, ÎîîÏûêÏù∏ÍπåÏßÄ Íµ¨ÏÉÅÌïòÎ©∞ ÎßåÎì§ÏóàÏúºÎãàÍπå ÏûêÏÑúÏ†ÑÏùò Í≤âÎ™®ÏäµÏùÄ ÌèâÎ≤îÌïòÍ≥† ÏÜåÎ∞ïÌñàÏñ¥. Í∑∏ÎûòÎèÑ Ïñ¥Î®∏ÎãàÍªòÏÑúÎäî ÏùºÏÉùÏù¥ Í≥†Ïä§ÎûÄÌûà Îã¥Í∏¥ Ï±ÖÏùÑ Î∞õÏïÑÎì§Í≥†Îäî Î¨¥Ï≤ô Ïã†Í∏∞Ìï¥ÌïòÍ≥† Í∏∞ÎªêÌïòÏÖ®Ïñ¥.\n",
    "# Ïñ¥Î®∏ÎãàÎäî Î∞∞Ïö∏ Í∏∞ÌöåÎ•º ÎßéÏù¥ Í∞ñÏßÄ Î™ªÌñàÏßÄÎßå Îäò Ï±ÖÏùÑ Í∞ÄÍπåÏù¥ÌïòÏÖ®Ïñ¥. ÏÇ≠ÎßâÌïòÍ≥† Îî±Îî±Ìïú ÏãúÎåÅÏùò Î¨∏ÌôîÏóê, Í≥µÎ¨¥Ïõê ÎÇ®Ìé∏Ïùò Î∞ïÎ¥âÏóê ÍøãÍøãÏù¥ ÎßûÏÑú ÏùºÏÉùÏùÑ Ï¢ÄÎçî ÌôúÍ∏∞Ï∞®Í≤å ÏÇ¨ÏÖ®Í≥† ÌäπÌûà Í∞ïÎã® ÏûàÍ≥† ÏöîÎ†π ÏûàÍ≤å ÏÑ∏ÏÉÅÍ≥º ÎßûÏß± Îñ†ÏÑú Í≥†Îã®ÌïòÎçò Í∞ÄÎÇúÏùÑ ÎÅäÏñ¥ÎÇ¥ÏÖ®Ïñ¥. ÏûêÏãù ÏÇº ÌòïÏ†úÎ•º Ï§ëÏÇ∞Ï∏µÏúºÎ°ú Ï¢Ä ÎßåÎì§Ïñ¥ÎëêÏãúÍ≥†, Ï±ÖÏûÑ ÏôÑÏàòÌïòÏã† ÏïÑÎ≤ÑÎãòÍªòÏÑú ÌôÄÍ∞ÄÎ∂ÑÌïú ÎßàÏùåÏúºÎ°ú Î®ºÏ†Ä Í∞ÄÏãúÎèÑÎ°ù Ïûò Î≥¥ÎÇ¥ÎìúÎ¶∞ ÌõÑÏóê Ïù¥Ï†ú Ïã†ÏïôÏóê Í∏∞ÎåÄÏñ¥ Îã®Ï†ïÌïú ÎÖ∏ÎÖÑÏùÑ Î≥¥ÎÇ¥Í≥† Í≥ÑÏÖî\n",
    "# Í∑∏Îü¨Îçò Ïñ¥Î®∏ÎãàÍªòÏÑú Ïñ∏Ï††Í∞ÄÎ∂ÄÌÑ∞ ÎÇ¥Í∞Ä Ïì∞ÏßÄ ÏïäÎäîÎã§Î©¥ÏÑú Í∞ÄÏ†∏Îã§ ÎìúÎ¶∞ Îπà Í≥µÏ±ÖÏóê Ïó∞ÌïÑÎ°ú ÍæπÍæπ ÎàåÎü¨Í∞ÄÎ©¥ÏÑú ÏßÄÎÇòÏò® Ïù¥ÏïºÍ∏∞Îì§ÏùÑ Í∏∞ÏñµÎÇòÎäî ÎåÄÎ°ú Ï°∞Í∏àÏî© Ïì∞Í∏∞ ÏãúÏûëÌïòÏÖ®ÎäîÎç∞, ÍπîÎÅîÌïòÍ≤å Ï†ïÎ¶¨Ìï¥ÏÑú Ï±ÖÏúºÎ°ú ÎßåÎì§Ïñ¥ ÎìúÎ¶¨Í≤†Îã§Î©∞ ÏõêÍ≥†Î•º Í∞ÄÏ†∏Îã§Í∞Ä ÌÉÄÏù¥ÌïëÌïòÍ∏∞ ÏãúÏûëÌñàÏñ¥\"\"\"\n",
    "\n",
    "# 3. Ï∂îÎ°† Ïã§Ìñâ\n",
    "sample_rate, waveform = run_tts(engine, input_text, prompt_audio_path, prompt_text)\n",
    "\n",
    "# 4. float32 ‚Üí int16Î°ú Î≥ÄÌôòÌïòÏó¨ Ï†ÄÏû•\n",
    "waveform_int16 = (waveform * 32767).astype(np.int16)\n",
    "write_wav(\"results/result.wav\", sample_rate, waveform_int16)\n",
    "\n",
    "print(\"‚úÖ ÏÉùÏÑ± ÏôÑÎ£å: result.wav\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4232b709",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
